# More C++ Semaphores
In C++ we can use two standard libraries to provide a convenient way to manage lock acquisition and release, ensuring that locks are properly released even in the presence of exceptions.

- lock_guard
- unique_lock

Both **std::lock_guard** and **std::unique_lock** are RAII (Resource Acquisition Is Initialization) wrappers for locks in C++


## lock_guard
**std::lock_guard** is a simple RAII wrapper for a lock. 

It acquires the lock during construction and releases it during destruction.

```cpp
#include <iostream>
#include <thread>
#include <mutex>

std::mutex myMutex;

void someFunction() {
    std::lock_guard<std::mutex> guard(myMutex);

    // Critical section
    std::cout << "Thread " << std::this_thread::get_id() << " is in the critical section." << std::endl;

    // The lock is automatically released when 'guard' goes out of scope.
}

int main() {
    std::thread t1(someFunction);
    std::thread t2(someFunction);

    t1.join();
    t2.join();

    return 0;
}
```

## unique_lock
***std::unique_lock** provides more flexibility than **std::lock_guard**. 

It allows for manual lock and unlock operations, **deferred locking**, and **condition variable** support.

```cpp
#include <iostream>
#include <thread>
#include <mutex>

std::mutex myMutex;

void someFunction() {
    std::unique_lock<std::mutex> lock(myMutex);

    // Critical section
    std::cout << "Thread " << std::this_thread::get_id() << " is in the critical section." << std::endl;

    // The lock is automatically released when 'lock' goes out of scope.
}

int main() {
    std::thread t1(someFunction);
    std::thread t2(someFunction);

    t1.join();
    t2.join();

    return 0;
}
```

> Choosing Between std::lock_guard and std::unique_lock
> - Use **std::lock_guard** when you don't need to manually unlock the mutex or deal with deferred locking.
> - Use **std::unique_lock** when you need more control over locking and unlocking, or when you want to use features like deferred locking or condition variables.

### Deferred Locking

Deferred locking refers to a situation where a mutex is created but not immediately locked. This allows you to control when the lock is acquired manually. 

```cpp
#include <iostream>
#include <thread>
#include <mutex>

std::mutex myMutex;
int sharedData = 0;

void incrementWithDeferredLock() {
    std::unique_lock<std::mutex> lock(myMutex, std::defer_lock);

    // Some non-critical section code

    lock.lock();  // Manually lock the mutex when needed

    // Critical section
    int localCopy = sharedData;
    localCopy++;
    std::this_thread::sleep_for(std::chrono::milliseconds(100));  // Simulate some work
    sharedData = localCopy;

    // Some more non-critical section code

    lock.unlock();  // Manually unlock the mutex
}

int main() {
    std::thread t1(incrementWithDeferredLock);
    std::thread t2(incrementWithDeferredLock);

    t1.join();
    t2.join();

    std::cout << "Final value of sharedData: " << sharedData << std::endl;

    return 0;
}
```
In this example, **std::unique_lock** is created with **std::defer_lock**. 

The lock is manually acquired with **lock.lock()** and released with **lock.unlock()**. This provides flexibility in managing the critical section within the code.

### Condition Variables

Condition variables are synchronization primitives that allow threads to wait for a certain condition to be met before proceeding.

They are often used in conjunction with locks (usually **std::unique_lock**) to **avoid busy waiting**.

```cpp
#include <iostream>
#include <thread>
#include <mutex>
#include <condition_variable>

std::mutex myMutex;
std::condition_variable cv;
bool dataReady = false;

void producer() {
    // Produce data
    {
        std::lock_guard<std::mutex> lock(myMutex);
        dataReady = true;
    }

    // Notify the consumer that data is ready
    cv.notify_one();
}

void consumer() {
    // Wait for data to be ready
    {
        std::unique_lock<std::mutex> lock(myMutex);
        cv.wait(lock, [] { return dataReady; });
    }

    // Consume the data
    std::cout << "Data consumed by thread " << std::this_thread::get_id() << std::endl;
}

int main() {
    std::thread producerThread(producer);
    std::thread consumerThread(consumer);

    producerThread.join();
    consumerThread.join();

    return 0;
}
```

In this example, **std::condition_variable** is used to synchronize the producer and consumer threads.

The consumer thread waits until the condition dataReady becomes true, and the producer thread notifies the consumer when the data is ready.

Using deferred locking and condition variables with **std::unique_lock** provides more control and flexibility in managing synchronization in complex scenarios where precise control over locking and waiting is required.

Two important functions associated with condition variables are **notify_one** and **notify_all**

#### Notify_one
When a thread calls **notify_one** on a condition variable, it wakes up one of the waiting threads (if any).

> The system chooses which thread to wake up, and it is not deterministic, it dependes on the operating system and its scheduling policies.

This is useful when multiple threads are waiting for a specific condition, but only one of them needs to proceed.

#### Notify_all
When a thread calls **notify_all** on a condition variable it wakes up all waiting threads.

> This ensures that all waiting threads are given a chance to check the condition and potentially proceed. However, it might lead to more contention and context switching.


So you could use **notify_one** when only one waiting thread needs to proceed and waking up more than one would be inefficient, and use **notify_all** when multiple waiting threads could potentially proceed, or when it is crucial to ensure that all waiting threads get a chance to reevaluate the condition.