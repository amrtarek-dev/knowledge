**Algorithm complexity** refers to the computational resources required by an algorithm to solve a problem, typically measured in terms of time or space (memory). The **Big-O notation** is used to describe the **asymptotic complexity** of an algorithm, focusing on its behavior as the input size grows, ignoring constant factors and lower-order terms.

### Time Complexity

Time complexity measures the amount of time an algorithm takes to complete as a function of the input size (denoted as nnn).

### Space Complexity

Space complexity measures the amount of memory an algorithm needs to run relative to the input size.

### Big-O Notation

Big-O notation provides an upper bound on the growth rate of an algorithm, capturing the worst-case scenario. It describes how the runtime or space requirements increase as the size of the input increases.

### Common Big-O Complexities

1. **Constant Time – O(1):**
    - The algorithm takes the same amount of time regardless of input size.
    - Example: Accessing an element in an array by index.
``` cpp
int x = arr[5]; // O(1)
```

2. **Logarithmic Time – O(log⁡n):**
	- The time increases logarithmically with input size. Often occurs in divide-and-conquer algorithms like binary search.
	- Example: Binary search.
``` cpp
int binarySearch(int arr[], int target, int low, int high) {
    while (low <= high) {
        int mid = low + (high - low) / 2;
        if (arr[mid] == target) return mid;
        else if (arr[mid] < target) low = mid + 1;
        else high = mid - 1;
    }
    return -1;  // O(log n)
}
```

3. **Linear Time – O(n):**
	- The time grows directly proportional to the size of the input.
	- Example: Traversing an array or a linked list.
``` cpp
int sum = 0;
for (int i = 0; i < n; ++i) sum += arr[i];  // O(n)
```

4. **Linearithmic Time – O(nlog⁡n):**
	- A combination of linear and logarithmic growth. This is typical of efficient sorting algorithms like Merge Sort or Heap Sort.
	- Example: Merge Sort.
``` cpp
void mergeSort(int arr[], int l, int r) {
    if (l >= r) return;
    int m = l + (r - l) / 2;
    mergeSort(arr, l, m);
    mergeSort(arr, m + 1, r);
    merge(arr, l, m, r);  // O(n log n)
}
```

5. **Quadratic Time – O(n^2):**
	- The time grows proportionally to the square of the input size. This occurs in algorithms with nested loops over the input.
	- Example: Bubble Sort.
``` cpp
for (int i = 0; i < n; ++i)
    for (int j = 0; j < n - i - 1; ++j)
        if (arr[j] > arr[j + 1]) swap(arr[j], arr[j + 1]);  // O(n^2)
```

6. **Cubic Time – O(n^3):**
    - Similar to quadratic time, but with three nested loops, which scales the time even faster as the input size increases.
    - Example: Algorithms involving 3D matrices.

7. **Exponential Time – O(2^n):**
    - The time doubles with each addition to the input size. Algorithms of this type are highly inefficient for large inputs.
    - Example: Solving the Towers of Hanoi problem.
``` cpp
void hanoi(int n, char from, char to, char aux) {
    if (n == 1) {
        // Move one disk
        return;
    }
    hanoi(n - 1, from, aux, to);
    hanoi(n - 1, aux, to, from);  // O(2^n)
}
```

8. **Factorial Time – O(n!):**
    - The time grows factorially with the input size. This is typical in problems like generating all possible permutations.
    - Example: Solving the Traveling Salesman Problem via brute force.

### Comparing Time Complexities

- O(1) < O(log⁡n)< O(n) < O(nlog⁡n) < O(n^2) < O(n^3) < O(2^n) < O(n!)

### Best, Worst, and Average Cases

- **Worst-case complexity**: The maximum time the algorithm takes for any input.
- **Best-case complexity**: The minimum time for some specific input.
- **Average-case complexity**: The expected time for a random input.

Big-O focuses on the worst-case, but algorithms can be analyzed for best and average cases as well.